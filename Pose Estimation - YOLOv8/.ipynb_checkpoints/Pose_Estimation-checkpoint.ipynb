{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/newb-dev-1008/Gait-Analysis/blob/main/Pose%20Estimation%20-%20YOLOv8/Pose_Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Or6vQQYskfW"
   },
   "source": [
    "# Pose estimation and keypoint detection:\n",
    "\n",
    "1. How did you annotate your data for training?\n",
    "\n",
    "**Ans:**\n",
    "Used this annotation tool for annotating training data: https://app.cvat.ai/.\n",
    "This is used to annotate 17 keypoints and to draw bounding boxes around the subject.\n",
    "\n",
    "2. What does the COCO keypoint annotation format look like?\n",
    "\n",
    "**Ans:**\n",
    "Refer section 2 (Keypoint Detection) under this website: https://cocodataset.org/#format-data\n",
    "\n",
    "**First value:** Label ID (If dataset has labels {car, person, dog} then {0: car, 1: person, 2: dog})\n",
    "\n",
    "**Second value:** [x, y, height, width] (x and y of the centre point of the bounding box; height and width of bounding box)\n",
    "\n",
    "**Third value onwards:** 17 [x, y] values - corresponding to x and y coordinates of 17 keypoints\n",
    "\n",
    "For explanation, watch https://youtu.be/gA5N54IO1ko?si=UkbL0vXXMc20tvIt (from 13:15 onwards to 18:50)\n",
    "\n",
    "For details on the COCO dataset: https://docs.ultralytics.com/datasets/pose/coco/\n",
    "\n",
    "To download COCO dataset: https://cocodataset.org/#download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1yFy91Vf0D_",
    "outputId": "3da07b30-f0cb-406e-af57-9b7f070d676a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.2.27-py3-none-any.whl (779 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.27\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7gG3LQEe3T9"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhbpuddRfsT5",
    "outputId": "7c041c27-8592-4eca-f485-1ffec1217b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.51M/6.51M [00:00<00:00, 78.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 397/397 items from pretrained weights\n",
      "Ultralytics YOLOv8.2.27 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.yaml, data=coco8-pose.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/pose/train\n",
      "\n",
      "Dataset 'coco8-pose.yaml' images not found âš ï¸, missing path '/content/datasets/coco8-pose/images/val'\n",
      "Downloading https://ultralytics.com/assets/coco8-pose.zip to '/content/datasets/coco8-pose.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 334k/334k [00:00<00:00, 8.43MB/s]\n",
      "Unzipping /content/datasets/coco8-pose.zip to /content/datasets/coco8-pose...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 2940.39file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success âœ… (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 14.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients, 9.3 GFLOPs\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/pose/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-pose/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 128.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-pose/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 2636.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/pose/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/pose/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G     0.9888      2.053     0.2933     0.7491        1.2          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.927      0.914      0.907      0.668      0.846        0.5      0.535      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100         0G      1.027      3.723     0.4694     0.8064       1.23         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.91      0.929      0.907      0.668      0.842        0.5      0.535      0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100         0G       1.18      3.614     0.4049      1.033      1.226         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.861      0.929      0.902      0.674      0.707      0.571      0.535      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100         0G      1.344      3.186     0.3136       0.87      1.295         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.849      0.929      0.893      0.664      0.714      0.571      0.526      0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100         0G     0.9053      1.784     0.2177     0.5168      1.125         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.847      0.929      0.908      0.658      0.723      0.571      0.533      0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100         0G     0.7404      1.882     0.3233     0.4792     0.9513         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.845      0.929      0.936      0.667      0.799      0.571      0.544      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100         0G      1.178      3.944     0.5677      1.021      1.292         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.841      0.929      0.933      0.651      0.792      0.571      0.536      0.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100         0G      1.052      2.208     0.4226     0.9743      1.046         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.849      0.929      0.944      0.641      0.772      0.571      0.524      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100         0G     0.9207      2.689     0.2639      0.621       1.28         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.864      0.911      0.926      0.628      0.646        0.5      0.437      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100         0G      1.036      3.039     0.4262     0.7188      1.138         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.786      0.929      0.898      0.595      0.627        0.5      0.404      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100         0G      1.185      1.893     0.2409     0.6913       1.32         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.789      0.929      0.875      0.587      0.622        0.5      0.396      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100         0G      1.159      4.118     0.4151      1.126      1.247         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.76      0.929      0.868      0.554      0.621        0.5      0.409      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100         0G      1.376      2.026     0.3078     0.7175      1.493          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.889      0.714      0.853      0.551      0.654      0.429      0.363      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100         0G      1.108      2.957     0.2793     0.7488       1.25         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.902      0.714      0.833      0.558      0.662      0.429      0.351      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100         0G     0.8412      1.024     0.2576     0.7611      1.149         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.737      0.714      0.818       0.54      0.672      0.441      0.402      0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100         0G      1.077      2.447     0.2751     0.8765       1.19         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14        0.7      0.714      0.787      0.501      0.801      0.357      0.338      0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100         0G      1.167      2.907     0.3255     0.7851      1.075         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.732      0.714      0.778      0.464      0.641      0.286      0.243     0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100         0G      1.085      2.433     0.2981     0.6849      1.044         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.732      0.714      0.778      0.464      0.641      0.286      0.243     0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100         0G      1.112      2.487     0.2659     0.7435      1.206         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.804      0.588      0.702      0.441       0.38      0.438      0.318     0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100         0G     0.8692      2.404     0.3119     0.6329      1.051         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.804      0.588      0.702      0.441       0.38      0.438      0.318     0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100         0G      1.412      2.361     0.3159      0.862      1.305         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.662      0.559      0.622      0.408       0.62      0.351      0.264     0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100         0G      1.021       1.99     0.2332     0.7954      1.181         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.662      0.559      0.622      0.408       0.62      0.351      0.264     0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100         0G      1.458      4.919     0.3379      1.852      1.585          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14          1       0.48      0.641      0.385      0.632      0.286      0.254      0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100         0G       1.12      2.579      0.288     0.8995      1.265          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14          1       0.48      0.641      0.385      0.632      0.286      0.254      0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100         0G      1.256      2.121     0.2974     0.7578      1.532          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.946        0.5      0.625      0.318      0.664      0.357      0.323     0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100         0G      1.064      2.784     0.3023     0.9343      1.256         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.946        0.5      0.625      0.318      0.664      0.357      0.323     0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100         0G      1.198      3.732     0.5565      1.319       1.45          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.694      0.429      0.525      0.256      0.459      0.286      0.247     0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100         0G     0.7999      2.238     0.3106     0.7488      1.003         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.694      0.429      0.525      0.256      0.459      0.286      0.247     0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100         0G     0.8179       2.65     0.2992     0.8317      1.145         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.83      0.429      0.547      0.257      0.553      0.286      0.263     0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100         0G      1.004      3.185     0.3848     0.8578      1.232          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.83      0.429      0.547      0.257      0.553      0.286      0.263     0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100         0G      1.029      3.276     0.4133     0.8661      1.141         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.84      0.429      0.554      0.281       0.56      0.286       0.21      0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100         0G       1.32      2.734     0.2661      1.107      1.217          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.84      0.429      0.554      0.281       0.56      0.286       0.21      0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100         0G       1.02      2.295     0.2185     0.9242      1.366         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.775        0.5      0.662      0.284      0.554      0.357      0.361     0.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100         0G     0.8693      2.705     0.3273     0.7742      1.048         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.775        0.5      0.662      0.284      0.554      0.357      0.361     0.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100         0G     0.8836      2.113     0.3105     0.7349      1.105         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.703      0.571      0.637      0.303      0.666      0.429      0.424      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100         0G     0.7302      2.376     0.2681     0.6803      1.074         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.703      0.571      0.637      0.303      0.666      0.429      0.424      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100         0G     0.9844      2.048      0.305     0.6627      1.135         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.887      0.563      0.636      0.312          1      0.353      0.415      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100         0G      0.793      2.593     0.3158     0.6781      1.075         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.887      0.563      0.636      0.312          1      0.353      0.415      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100         0G     0.7643      1.908     0.2861     0.6384      1.076          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.718      0.548      0.566      0.278      0.532      0.408       0.38      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100         0G     0.7656      2.341     0.2882     0.6197     0.9817         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.718      0.548      0.566      0.278      0.532      0.408       0.38      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100         0G     0.9213      2.929     0.3157     0.6469      1.163         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.578        0.5      0.497      0.251      0.649      0.286      0.278     0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100         0G      1.091      2.151     0.2959     0.7789      1.158         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.578        0.5      0.497      0.251      0.649      0.286      0.278     0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100         0G     0.7134      2.355     0.3397     0.5272       1.04          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.579        0.5      0.536      0.291       0.65      0.286      0.274     0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100         0G     0.7544      2.042     0.2173     0.6458      1.144          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.579        0.5      0.536      0.291       0.65      0.286      0.274     0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100         0G     0.8029      2.374     0.3005     0.6596      1.102         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.825        0.5      0.588      0.307      0.779      0.286      0.279     0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100         0G      1.083      2.401      0.321     0.7961      1.111         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.825        0.5      0.588      0.307      0.779      0.286      0.279     0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100         0G     0.6395      2.842     0.2249     0.5821     0.9641         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.842        0.5      0.583      0.287      0.777      0.286      0.257      0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100         0G      1.359      2.544     0.3886      1.384      1.456         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.842        0.5      0.583      0.287      0.777      0.286      0.257      0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100         0G      0.728      2.102     0.3469     0.6385      1.103         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.656        0.5      0.542      0.283      0.649      0.357      0.352     0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100         0G      1.027       2.96     0.2826     0.7572       1.21         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.656        0.5      0.542      0.283      0.649      0.357      0.352     0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100         0G      1.028      3.081     0.3826     0.8093      1.119         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.796        0.5      0.562      0.289      0.818      0.357       0.35     0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100         0G     0.8535      3.312     0.2732     0.7272      1.032         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  5.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.796        0.5      0.562      0.289      0.818      0.357       0.35     0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100         0G     0.9639      2.677     0.2513     0.9025      1.089         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.796        0.5      0.562      0.289      0.818      0.357       0.35     0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100         0G     0.9706      2.222     0.3623     0.7823      1.109         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.661        0.5      0.525      0.255      0.391      0.286      0.183     0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100         0G     0.8398      3.462     0.3029     0.7059      1.109         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.661        0.5      0.525      0.255      0.391      0.286      0.183     0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100         0G      1.131      3.686     0.2788     0.8347      1.173         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.661        0.5      0.525      0.255      0.391      0.286      0.183     0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100         0G     0.8334      2.567     0.2653     0.6346       1.19          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.555      0.571      0.543      0.245      0.499      0.285       0.23     0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100         0G     0.7644      2.554     0.3437     0.6455     0.9292         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.555      0.571      0.543      0.245      0.499      0.285       0.23     0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100         0G     0.9176      2.861     0.3119     0.7305      1.038         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.555      0.571      0.543      0.245      0.499      0.285       0.23     0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100         0G     0.8093      3.505     0.3428     0.8751       1.02         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.625        0.5       0.51      0.219      0.465      0.143      0.133     0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100         0G     0.7781      2.657     0.2955      0.813      1.148         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.625        0.5       0.51      0.219      0.465      0.143      0.133     0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100         0G      1.068      1.937     0.3404     0.8581      1.124         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.625        0.5       0.51      0.219      0.465      0.143      0.133     0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100         0G     0.7902      1.867     0.2235     0.6461      1.073         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.666      0.429       0.49      0.216       0.13      0.149     0.0614     0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100         0G     0.8661      2.903     0.2588       0.81      1.068          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.666      0.429       0.49      0.216       0.13      0.149     0.0614     0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100         0G     0.8096      1.829     0.2585     0.6625     0.9471         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.666      0.429       0.49      0.216       0.13      0.149     0.0614     0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100         0G       0.76       2.15     0.2475     0.7219      1.014         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.588      0.429      0.479      0.216      0.169      0.214     0.0798     0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100         0G     0.9155       1.99     0.3055     0.7123      1.113         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.588      0.429      0.479      0.216      0.169      0.214     0.0798     0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100         0G     0.9186      2.474     0.2661     0.8686      1.139         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.588      0.429      0.479      0.216      0.169      0.214     0.0798     0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100         0G     0.7148      2.819     0.3895     0.6093     0.9998         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.644      0.429      0.522      0.231      0.651      0.143      0.173     0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100         0G     0.8708      1.828     0.3388     0.7305      1.119         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.644      0.429      0.522      0.231      0.651      0.143      0.173     0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100         0G       1.02      3.392     0.4188     0.8854      1.196         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.644      0.429      0.522      0.231      0.651      0.143      0.173     0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100         0G     0.9637       2.87     0.2924      0.771      1.084         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.681      0.429        0.5      0.251      0.952      0.214      0.227     0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100         0G     0.6764      2.523     0.2253     0.6441     0.9973         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.681      0.429        0.5      0.251      0.952      0.214      0.227     0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100         0G     0.7863      1.858     0.3014     0.6475     0.9829         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.681      0.429        0.5      0.251      0.952      0.214      0.227     0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100         0G     0.7016      2.144     0.3275      0.594     0.9819         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.618        0.5       0.57       0.26      0.935      0.214      0.228     0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100         0G     0.6009      1.674     0.2977     0.5198     0.9813         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.618        0.5       0.57       0.26      0.935      0.214      0.228     0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100         0G     0.9011      3.519      0.343     0.6669      1.135         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.618        0.5       0.57       0.26      0.935      0.214      0.228     0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100         0G     0.9328      2.956     0.2588     0.7217      1.119         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.706      0.515      0.615      0.254      0.936      0.214      0.228     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100         0G     0.6632      2.035     0.2935     0.5543      1.051         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.706      0.515      0.615      0.254      0.936      0.214      0.228     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100         0G     0.7309      1.774      0.262     0.6434     0.9846         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.706      0.515      0.615      0.254      0.936      0.214      0.228     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100         0G     0.6402      1.979     0.3895     0.5296      1.004         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.66      0.555       0.62      0.238      0.932      0.214      0.228     0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100         0G     0.6909       2.45     0.3581     0.6951      1.044          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.66      0.555       0.62      0.238      0.932      0.214      0.228     0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100         0G     0.6611      1.783     0.3153     0.6061     0.9546         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14       0.66      0.555       0.62      0.238      0.932      0.214      0.228     0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100         0G     0.5747      1.207     0.2517     0.5516     0.8516         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.569      0.565      0.557      0.207      0.918      0.214      0.228     0.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100         0G     0.6919      2.363     0.3102     0.5565       1.03         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.569      0.565      0.557      0.207      0.918      0.214      0.228     0.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100         0G      0.702      1.871     0.2969      0.596      1.038          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.569      0.565      0.557      0.207      0.918      0.214      0.228     0.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100         0G     0.6444      1.356     0.2761     0.4577     0.9696         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.569      0.565      0.557      0.207      0.918      0.214      0.228     0.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100         0G     0.7781      1.588     0.3034     0.6196      1.025         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.623        0.5      0.584      0.226      0.904      0.214       0.23     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100         0G     0.6669      2.017     0.3454     0.6273     0.9296         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.623        0.5      0.584      0.226      0.904      0.214       0.23     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100         0G     0.8191      3.055     0.2785     0.7873      1.195         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.623        0.5      0.584      0.226      0.904      0.214       0.23     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100         0G      0.555      1.038     0.2501     0.4748     0.9559          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.623        0.5      0.584      0.226      0.904      0.214       0.23     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100         0G     0.5354      1.023     0.2289     0.4982     0.9408          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.777      0.497      0.611      0.251       0.82      0.143      0.155     0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100         0G     0.5642      1.476     0.2976     0.4206     0.8157          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.777      0.497      0.611      0.251       0.82      0.143      0.155     0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100         0G     0.4571      1.141       0.22     0.4312     0.8739          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.777      0.497      0.611      0.251       0.82      0.143      0.155     0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100         0G     0.4736     0.8684     0.2413     0.3679     0.9807          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.777      0.497      0.611      0.251       0.82      0.143      0.155     0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100         0G     0.4906     0.9726     0.2624     0.5043     0.9612          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.693      0.485      0.568      0.246       0.87      0.143      0.155     0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100         0G     0.7321      1.551     0.2358     0.7309      1.007          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.693      0.485      0.568      0.246       0.87      0.143      0.155     0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100         0G     0.5687      1.222     0.2596     0.5958     0.9244          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.693      0.485      0.568      0.246       0.87      0.143      0.155     0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100         0G     0.6552      2.192     0.2577     0.5054        1.1          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.693      0.485      0.568      0.246       0.87      0.143      0.155     0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100         0G     0.6545       1.36     0.2237     0.4649     0.9184          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14          1      0.424      0.617      0.269      0.867      0.143      0.154     0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.171 hours.\n",
      "Optimizer stripped from runs/pose/train/weights/last.pt, 6.9MB\n",
      "Optimizer stripped from runs/pose/train/weights/best.pt, 6.8MB\n",
      "\n",
      "Validating runs/pose/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.848      0.929      0.897      0.671      0.707      0.571      0.535      0.362\n",
      "Speed: 2.4ms preprocess, 262.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/pose/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n-pose.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolov8n-pose.pt\")  # load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolov8n-pose.yaml\").load(\"yolov8n-pose.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"coco8-pose.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKAptxA6jh6h",
    "outputId": "ca98bdd5-b187-413f-8bc0-8c64fd58ef3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/runs/ (stored 0%)\n",
      "  adding: content/runs/pose/ (stored 0%)\n",
      "  adding: content/runs/pose/train/ (stored 0%)\n",
      "  adding: content/runs/pose/train/BoxP_curve.png (deflated 17%)\n",
      "  adding: content/runs/pose/train/labels.jpg (deflated 58%)\n",
      "  adding: content/runs/pose/train/BoxPR_curve.png (deflated 27%)\n",
      "  adding: content/runs/pose/train/train_batch91.jpg (deflated 8%)\n",
      "  adding: content/runs/pose/train/train_batch2.jpg (deflated 2%)\n",
      "  adding: content/runs/pose/train/BoxR_curve.png (deflated 17%)\n",
      "  adding: content/runs/pose/train/PoseF1_curve.png (deflated 17%)\n",
      "  adding: content/runs/pose/train/PoseP_curve.png (deflated 16%)\n",
      "  adding: content/runs/pose/train/confusion_matrix.png (deflated 42%)\n",
      "  adding: content/runs/pose/train/events.out.tfevents.1717223688.215a91bc6484.142.0 (deflated 85%)\n",
      "  adding: content/runs/pose/train/labels_correlogram.jpg (deflated 63%)\n",
      "  adding: content/runs/pose/train/val_batch0_pred.jpg (deflated 10%)\n",
      "  adding: content/runs/pose/train/train_batch92.jpg (deflated 5%)\n",
      "  adding: content/runs/pose/train/results.csv (deflated 88%)\n",
      "  adding: content/runs/pose/train/PoseR_curve.png (deflated 21%)\n",
      "  adding: content/runs/pose/train/results.png (deflated 5%)\n",
      "  adding: content/runs/pose/train/val_batch0_labels.jpg (deflated 10%)\n",
      "  adding: content/runs/pose/train/confusion_matrix_normalized.png (deflated 37%)\n",
      "  adding: content/runs/pose/train/train_batch90.jpg (deflated 6%)\n",
      "  adding: content/runs/pose/train/BoxF1_curve.png (deflated 15%)\n",
      "  adding: content/runs/pose/train/train_batch0.jpg (deflated 0%)\n",
      "  adding: content/runs/pose/train/train_batch1.jpg (deflated 2%)\n",
      "  adding: content/runs/pose/train/weights/ (stored 0%)\n",
      "  adding: content/runs/pose/train/weights/last.pt (deflated 9%)\n",
      "  adding: content/runs/pose/train/weights/best.pt (deflated 9%)\n",
      "  adding: content/runs/pose/train/PosePR_curve.png (deflated 28%)\n",
      "  adding: content/runs/pose/train/args.yaml (deflated 53%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/results.zip /content/runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "OqxoDtW-gd_c",
    "outputId": "0448e98f-a30e-47c7-d3f2-c10407c154d9"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e4a9a1f3-8570-464d-8be8-d90bf6490410\", \"results.zip\", 16041040)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: absl-py in c:\\users\\yash umale\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (0.12.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (0.4.28)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (0.4.28)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (4.5.1.48)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.14.4)\n",
      "Requirement already satisfied: six in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax->mediapipe) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\yash umale\\appdata\\roaming\\python\\python39\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax->mediapipe) (1.13.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax->mediapipe) (7.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mediapipe) (8.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.18.1)\n",
      "Requirement already satisfied: imutils in c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.4)\n",
      "Collecting protobuf==3.20.0\n",
      "  Using cached protobuf-3.20.0-cp39-cp39-win_amd64.whl.metadata (699 bytes)\n",
      "Using cached protobuf-3.20.0-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed protobuf-3.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yash Umale\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\google\\~-pb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.7.0 requires flatbuffers<3.0,>=1.12, but you have flatbuffers 24.3.25 which is incompatible.\n",
      "mediapipe 0.10.14 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 24.3.25 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires numpy~=1.19.2, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.7.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.11.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "!pip install imutils\n",
    "!pip install protobuf==3.20.0"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette extraction\n",
    "\n",
    "Implementation from: https://github.com/jordankzf/human-silhouette-extractor\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create segmentation mask\n",
    "def makeSegMask(img, model):\n",
    "    \n",
    "    # Apply preprocessing (normalization)\n",
    "    preprocess = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "    \n",
    "    # Segment people only for the purpose of human silhouette extraction\n",
    "    people_class = 15\n",
    "    \n",
    "    blur = torch.FloatTensor([[[[1.0, 2.0, 1.0],[2.0, 4.0, 2.0],[1.0, 2.0, 1.0]]]]) / 16.0\n",
    "    \n",
    "    # Use GPU if supported, for better performance\n",
    "    if torch.cuda.is_available():\n",
    "        model.to('cuda')\n",
    "        blur = blur.to('cuda')\n",
    "    \n",
    "    # Scale input frame\n",
    "    frame_data = torch.FloatTensor( img ) / 255.0\n",
    "    input_tensor = preprocess(frame_data.permute(2, 0, 1))\n",
    "    \n",
    "    # Create mini-batch to be used by the model\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Use GPU if supported, for better performance\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "        \n",
    "    segmentation = output.argmax(0)\n",
    "    bgOut = output[0:1][:][:]\n",
    "    a = (1.0 - F.relu(torch.tanh(bgOut * 0.30 - 1.0))).pow(0.5) * 2.0\n",
    "    people = segmentation.eq( torch.ones_like(segmentation).long().fill_(people_class) ).float()\n",
    "    people.unsqueeze_(0).unsqueeze_(0)\n",
    "    \n",
    "    for i in range(3):\n",
    "        people = F.conv2d(people, blur, stride=1, padding=1)\n",
    "        \n",
    "    # Activation function to combine masks - F.hardtanh(a * b)\n",
    "    combined_mask = F.relu(F.hardtanh(a * (people.squeeze().pow(1.5)) ))\n",
    "    combined_mask = combined_mask.expand(1, 3, -1, -1)\n",
    "    res = (combined_mask * 255.0).cpu().squeeze().byte().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract silhouette from input frame\n",
    "def silhouetteFrames(imgRGB, model):\n",
    "    \n",
    "    img = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Apply background subtraction to extract foreground (silhouette)\n",
    "    mask = makeSegMask(img, model)\n",
    "    \n",
    "    # Apply thresholding to convert mask to binary map\n",
    "    ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Show extracted silhouette only, by multiplying mask and input frame\n",
    "    # final = cv2.bitwise_and(thresh, img)\n",
    "    \n",
    "    # Save output frame with the timestamp as name\n",
    "    cTime = time.time()\n",
    "    saveImageName = str(cTime) + \".jpg\"\n",
    "    \n",
    "    return mask, saveImageName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_HH0U2WjUzz"
   },
   "source": [
    "## Running the trained models with input video\n",
    "\n",
    "The trained models will work simultaneously on an input video to\n",
    "\n",
    "* generate skeletal frame for subject in the video.\n",
    "* extract silhouette for subject in the video.\n",
    "\n",
    "**Expected outputs:**\n",
    "\n",
    "1. Original video with keypoints and skeletal frame overlay.\n",
    "2. A simultaneous video of pose sequence, and a simultaneous video of extracted silhouette.\n",
    "3. The video outputs and frames will be written to disk in `/silhouette_frames` and `/skeleton_frames` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from imutils.video import VideoStream\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to input image and output extracted skeleton frame\n",
    "def skeletonFrames(imgRGB):\n",
    "    \n",
    "    # MediaPipe objects to help draw skeletons and keypoints\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    mpPose = mp.solutions.pose\n",
    "    pose = mpPose.Pose()\n",
    "    \n",
    "    img = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2BGR)\n",
    "    results = pose.process(imgRGB)\n",
    "    \n",
    "    # Create a blank image to draw landmarks on it\n",
    "    im_H, im_W, im_C = img.shape\n",
    "    blankImg = np.ones((im_H, im_W, im_C), dtype = np.uint8)\n",
    "    blankImg = 255 * blankImg\n",
    "    \n",
    "    # Overlay the skeleton with keypoints on video stream\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(blankImg, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "    \n",
    "        # Get the array of 17 keypoints necessary for input to ResGCN\n",
    "        lmList = []\n",
    "        required_keypoints = [0, 2, 5, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]\n",
    "        for id1, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = lm.x * w, lm.y * h\n",
    "            if id1 in required_keypoints:\n",
    "                lmList = lmList + [cx, cy]\n",
    "    \n",
    "    # Concatenate the timestamp with the list of landmarks at that particular time instant\n",
    "    cTime = time.time()\n",
    "    saveImageName = str(cTime) + \".jpg\"\n",
    "    temp_list = [saveImageName] + lmList\n",
    "    \n",
    "    return temp_list, blankImg, img, saveImageName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save all keypoints to CSV\n",
    "def saveSkeletonKeypointsCSV(outDir, lm_TimestepList):\n",
    "    \n",
    "    # Path to CSV file where all data for this VideoStream will be stored\n",
    "    csvFolder = outDir + \"\\\\csv\\\\\"\n",
    "    csvFilePath = csvFolder + videoFilePath.split('\\\\')[-1].rstrip(\".mp4\") + \".csv\"\n",
    "    \n",
    "    if not os.path.exists(csvFolder):\n",
    "        os.makedirs(csvFolder)\n",
    "        \n",
    "    fields = [\"timestep\", \n",
    "              \"nose_x\", \n",
    "              \"nose_y\", \n",
    "              \"left_eye_x\", \n",
    "              \"left_eye_y\", \n",
    "              \"right_eye_x\", \n",
    "              \"right_eye_y\", \n",
    "              \"left_ear_x\", \n",
    "              \"left_ear_y\", \n",
    "              \"right_ear_x\", \n",
    "              \"right_ear_y\", \n",
    "              \"left_shoulder_x\", \n",
    "              \"left_shoulder_y\", \n",
    "              \"right_shoulder_x\", \n",
    "              \"right_shoulder_y\", \n",
    "              \"left_elbow_x\", \n",
    "              \"left_elbow_y\", \n",
    "              \"right_elbow_x\", \n",
    "              \"right_elbow_y\", \n",
    "              \"left_wrist_x\",\n",
    "              \"left_wrist_y\", \n",
    "              \"right_wrist_x\", \n",
    "              \"right_wrist_y\", \n",
    "              \"left_hip_x\", \n",
    "              \"left_hip_y\", \n",
    "              \"right_hip_x\", \n",
    "              \"right_hip_y\", \n",
    "              \"left_knee_x\", \n",
    "              \"left_knee_y\", \n",
    "              \"right_knee_x\",\n",
    "              \"right_knee_y\", \n",
    "              \"left_ankle_x\", \n",
    "              \"left_ankle_y\", \n",
    "              \"right_ankle_x\", \n",
    "              \"right_ankle_y\"]\n",
    "\n",
    "    # Save to CSV File\n",
    "    with open(csvFilePath, \"w\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Header row\n",
    "        writer.writerow(fields)\n",
    "\n",
    "        # Write all the main content\n",
    "        writer.writerows(lm_TimestepList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take input video and output files + live output stream with skeleton and silhouette\n",
    "def processVideo(liveFromCamera, videoPath, outDir, saveAsVideo):\n",
    "    \n",
    "    # -------- Fixing I/O paths --------\n",
    "    # Directory where skeleton frames will be stored\n",
    "    outSkeletonDir = outDir + \"\\\\\" + \"skeleton_frames\"\n",
    "\n",
    "    # Directory where silhouette frames will be stored\n",
    "    outSilhouetteDir = outDir + \"\\\\\" + \"silhouette_frames\"\n",
    "    \n",
    "    if not os.path.exists(outSkeletonDir):\n",
    "        os.makedirs(outSkeletonDir)\n",
    "    \n",
    "    if not os.path.exists(outSilhouetteDir):\n",
    "        os.makedirs(outSilhouetteDir)\n",
    "    # ----------------------------------\n",
    "    \n",
    "    # Load silhouette extraction ResNet model (careful - this downloads 230MB of model the first time you run it)\n",
    "    # After execution, you can delete the downloaded model in C:\\Users\\<user>\\.cache\\torch\\\n",
    "    model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "    \n",
    "    # Load the silhouette extraction model\n",
    "    model.eval()\n",
    "    \n",
    "    # Take input from either webcam or input file, based on choice entered by user\n",
    "    if (liveFromCamera):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(videoPath)\n",
    "    \n",
    "    # If you wish to save the outputs as video along with the frames that will be generated\n",
    "    if (saveAsVideo):\n",
    "        # Create new output video files for both skeleton and silhouette outputs\n",
    "        outVid_Skl_Path = outSkeletonDir + \"\\\\\" + str(time.time()) + \"_skl.mp4\"\n",
    "        outVid_Sil_Path = outSilhouetteDir + \"\\\\\" + str(time.time()) + \"_sil.mp4\"\n",
    "        out_skl = cv2.VideoWriter(outVid_Skl_Path, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "        out_sil = cv2.VideoWriter(outVid_Sil_Path, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "    \n",
    "    # Save landmarks for each timestep in a CSV file, but before that, save it in the below list\n",
    "    lm_TimestepList = []\n",
    "\n",
    "    # While the livestream is ON, or while the input video file hasn't ended\n",
    "    success = True\n",
    "    while (True and success):\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if img is None:\n",
    "            break\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # -------- <Skeleton image outputs> --------\n",
    "        \n",
    "        skKeyPointList, skImage, overlayImage, skImgName = skeletonFrames(imgRGB)\n",
    "        \n",
    "        # Save these timestamp details (landmarks at that particular timestamp) to a list, \n",
    "        # then write them to a CSV file once VideoStream ends\n",
    "        lm_TimestepList.append(skKeyPointList)\n",
    "        \n",
    "        # -------- </Skeleton image outputs> --------\n",
    "        \n",
    "        # -------- <Silhouette extraction outputs> -------\n",
    "        silImage, silImgName = silhouetteFrames(imgRGB, model)\n",
    "        # -------- </Silhouette extraction outputs> --------\n",
    "        \n",
    "        # ------ Save the images to file ------\n",
    "        saveSkImgPath = outSkeletonDir + \"\\\\\" + skImgName\n",
    "        saveSilImgPath = outSilhouetteDir + \"\\\\\" + silImgName\n",
    "        cv2.imwrite(saveSkImgPath, skImage)\n",
    "        cv2.imwrite(saveSilImgPath, silImage)\n",
    "        if (saveAsVideo):\n",
    "            out_skl.write(skImage)\n",
    "            out_sil.write(silImage)\n",
    "        # -------------------------------------\n",
    "        \n",
    "        \n",
    "        if (liveFromCamera):\n",
    "            # ------ If input is a livestream, we want three live outputs on the screen ------\n",
    "            cv2.imshow(\"Overlay Pose Estimation\", overlayImage)\n",
    "            cv2.imshow(\"Pose Estimation with Skeleton\", skImage)\n",
    "            cv2.imshow(\"Silhouette Extraction\", silImage)\n",
    "            # --------------------------------------------------------------------------------\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "            # If you enter \"Q\" or \"q\", the VideoStream will quit.\n",
    "            if (key == ord(\"q\") or key == ord('Q')):\n",
    "                break\n",
    "    \n",
    "    # Release resources\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    if (saveAsVideo):\n",
    "        out_skl.release()\n",
    "        out_sil.release()\n",
    "    \n",
    "    # Save keypoints to CSV\n",
    "    saveSkeletonKeypointsCSV(outDir, lm_TimestepList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the following input paths for the model\n",
    "\n",
    "These paths are necessary for both models to generate and store their output frames.\n",
    "\n",
    "`videoFilePath`: Enter the full absolute path to the video file.\n",
    "\n",
    "`outputParentDir`: Enter the path to folder which will contain all output frames. All subdirectories will be created automatically for each input video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter file path of input video within quotes below.\n",
    "videoFilePath = r'C:\\Users\\Yash Umale\\Pictures\\Camera Roll\\test.mp4'\n",
    "\n",
    "# Enter output directory path (path to folder) below\n",
    "outputParentDir = r'C:\\Users\\Yash Umale\\Pictures\\GaitAnalysis\\out' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the output directory, we store the frames for each video\n",
    "outputDir = outputParentDir + '\\\\' + videoFilePath.split('\\\\')[-1].rstrip(\".mp4\")\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live video input? (y/n): n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Yash Umale/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\users\\yash umale\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "choice = str(input(\"Live video input? (y/n): \"))\n",
    "\n",
    "# Change this as necessary; set this to False as it slows down the rest of the process\n",
    "saveAsVideo = False\n",
    "\n",
    "if ((choice == 'y') or (choice == 'Y')):\n",
    "    processVideo(True, \"\", outputDir, saveAsVideo)\n",
    "else:\n",
    "    processVideo(False, videoFilePath, outputDir, saveAsVideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO43tgWGI0kSKC6GnGna/Xh",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
